#!/usr/bin/env python
# coding: utf-8

# # dev_veces_mora automatizado

# ## Instalar librerias

# In[1]:


pip install awswrangler


# In[2]:


get_ipython().system('pip install odfpy')


# In[3]:


pip install boto3 botocore


# ## Importar librerias

# In[4]:


import numpy as np
from datetime import datetime
import awswrangler as wr
import pandas as pd
import calendar
import datetime
from datetime import datetime
from datetime import date
import pytz
from datetime import timedelta
from dateutil.relativedelta import relativedelta
import boto3
from botocore.exceptions import ClientError


# ## Conexion a redshift

# In[5]:


con_redshift_2 = wr.redshift.connect("redshift_cctp_inovation")
conn = wr.redshift.connect("redshift_devsie")


# ## Variables para la creación de las tablas

# ### Obtener fecha del día de hoy, de seis meses atras y de doce meses atras

# In[6]:


# Set the time zone to Mexico City
mexico_timezone = pytz.timezone('America/Mexico_City')

# Get the current datetime in Mexico City
current_datetime = datetime.now(mexico_timezone)

# Extract the date
current_date = current_datetime.date()
previous_date=current_datetime.date() - relativedelta(days=1)
six_months_ago=previous_date - relativedelta(months=6)
twelve_months_ago=previous_date - relativedelta(months=12)

# Convert the datetime object back to a formatted string
previous_date= previous_date.strftime("%Y%m%d")
six_months_ago = six_months_ago.strftime("%Y%m%d")
twelve_months_ago= twelve_months_ago.strftime("%Y%m%d")


# Corvert the datetimes to a formated int 
previous_date = int(previous_date)
six_months_ago = int(six_months_ago)
twelve_months_ago = int(twelve_months_ago)


# Print the result in a formatted way
print("día vencido:",previous_date )
print("Seis meses atras del día vencido", six_months_ago)
print("Doce meses atras del día vencido", twelve_months_ago)


# ## Validar si en las base black_box.cartera hay información a día vencido

# In[7]:


sql1 = f"""
           select 
                 cuenta,fecha_informacion
           from black_box.cartera
           where fecha_informacion={previous_date}
           limit 100;
               """


# In[8]:


df1 = wr.redshift.read_sql_query(sql1,conn)


# ## Validar si en las base black_box.cartera hay información de un año atras

# In[9]:


sql2 = f"""
           select 
                 cuenta,fecha_informacion
           from black_box.cartera
           where fecha_informacion={twelve_months_ago}
           limit 100;
               """


# In[10]:


df2 = wr.redshift.read_sql_query(sql2,conn)


# ## Validar si existe la carpeta en S3

# In[11]:


s3_client = boto3.client('s3')


# In[12]:


def check_s3_folder(bucket_name, folder_name):
    try:
        response = s3_client.head_object(Bucket=bucket_name, Key=folder_name + '/')
    except ClientError as e:
        if e.response['Error']['Code'] == '404':
            return False
        else:
            raise
    return True


# In[13]:


bucket_name = 'desarrollos-bigdata-inovacion-us-east-1'
folder_name = f'SAS/sas94/dev_veces_mora/{previous_date}'


# ## Subir la tabla dev_veces_mora a S3 en formato parquet

# In[14]:


if not df1.empty:
    if not df2.empty:
        if not check_s3_folder(bucket_name, folder_name):
            sql = f"""UNLOAD ($$
                        select 
                        cuenta,
                        compania,
                        substring(fecha_informacion, 1,4) as anno,
                        substring(fecha_informacion, 5,2) as mes,
                        substring(fecha_informacion, 7,2) as dia,
                        morosidad ,
                        atraso
                        from black_box.cartera
                        where fecha_informacion>={twelve_months_ago} and  fecha_informacion<={previous_date}
                        $$)
                        TO 's3://desarrollos-bigdata-inovacion-us-east-1/SAS/sas94/dev_veces_mora/{previous_date}/'
                        IAM_ROLE 'arn:aws:iam::903746939682:role/ReadTP'
                        PARALLEL OFF
                        FORMAT PARQUET
               """
            df = wr.redshift.read_sql_query(sql,con_redshift_2)
        else:
            print("Ya existe la carpeta en S3.")
    else:
        print("No hay información en la base black_box.cartera para el día",one_year_ago)
else:
    print("No hay información en la base black_box.cartera para el día",previous_date)
